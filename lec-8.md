# ğŸ“Š Data Science â€” Lecture 8 Summary

### 1. Recap

* Parameter estimation (MLE & MAP).
* Example: biased coin probability.
* Bayesâ€™ rule applications.

---

### 2. Concentration Inequalities

Tools to bound probability of rare events (large deviations from expectation).

#### ğŸ”¹ Markovâ€™s Inequality

* For non-negative random variable X:
  **P(X â‰¥ a) â‰¤ E\[X] / a**

**Example:** Toss biased coin (p=0.2) 100 times â†’ E\[X]=20.

* Probability of â‰¥50 heads: 20/50 = 0.4.
* So with probability â‰¥0.6, heads â‰¤50.

ğŸ‘‰ Simple but often too loose.

---

#### ğŸ”¹ Chebyshevâ€™s Inequality

* Uses variance:
  **P(|Xâˆ’Î¼| â‰¥ k) â‰¤ Var(X) / kÂ²**

**Example:** Same coin (p=0.2, n=100).

* Î¼ = 20, Var = 16.
* Deviation â‰¥30 â†’ Bound = 16/900 â‰ˆ 0.017.
* So with probability â‰¥98.3%, heads â‰¤50.

ğŸ‘‰ Much tighter than Markov.

---

#### ğŸ”¹ Chernoff Bounds

* Even stronger, especially for sums of independent RVs.
* Gives exponentially decreasing tails.
* Widely used in CS (randomized algorithms, network reliability).

---

### 3. Applications

#### 1. Captcha Database Verification

* Claim: 1M unique captchas.
* If you test m captchas, expected duplicates â‰ˆ mÂ² / (2n).
* Example: m=1000 â†’ check duplicates to verify claim.

ğŸ‘‰ Based on **Birthday paradox** idea.

#### 2. Die Rolls Coverage

* For k-sided die, expected rolls to see all faces â‰ˆ k ln(k).
* By Markov: with probability â‰¥2/3, all faces appear in â‰¤3k ln(k) rolls.

#### 3. Job Interviews (Markov weakness)

* Friend says: 20% chance per company Ã— 4 companies â†’ claims 80% chance of â‰¥1 offer.
* True probability = 1 âˆ’ (0.8â´) = 0.5904 (â‰ˆ59%).
* Shows Markov bound can be misleadingly weak.

---

### 4. Moments Refresher

* **1st moment:** Mean = E\[X].
* **2nd moment:** Variance = E\[XÂ²] âˆ’ (E\[X])Â².
* **Variance of sum:** Var(X+Y) = Var(X)+Var(Y)+2Cov(X,Y).
* If independent â†’ Var(X+Y) = Var(X)+Var(Y).

---

## âœ… Key Takeaways

* **Markov inequality:** simple bound using mean.
* **Chebyshev inequality:** variance-based, tighter.
* **Chernoff bounds:** exponential decay, strongest.
* Applications: captcha verification, die rolls, interview/job probabilities.

ğŸ‘‰ Concentration inequalities are essential in **probability, ML theory, and randomized algorithms**.
